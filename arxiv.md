
# arxiv

|#|id|title|note|
|-|-|-|-|
|1|[1312.2249](http://cn.arxiv.org/abs/1312.2249)|Scalable Object Detection using Deep Neural Networks||
|2|[1409.1556](http://cn.arxiv.org/abs/1409.1556)|Very Deep Convolutional Networks for Large-Scale Image Recognition||
|3|[1409.4842](http://cn.arxiv.org/abs/1409.4842)|Going Deeper with Convolutions||
|4|[1502.03167](http://cn.arxiv.org/abs/1502.03167)|Batch Normalization: Accelerating Deep Network Training by Reducing  Internal Covariate Shift||
|5|[1503.03832](http://cn.arxiv.org/abs/1503.03832)|FaceNet: A Unified Embedding for Face Recognition and Clustering|facenet|
|6|[1512.00567](http://cn.arxiv.org/abs/1512.00567)|Rethinking the Inception Architecture for Computer Vision||
|7|[1512.03385](http://cn.arxiv.org/abs/1512.03385)|Deep Residual Learning for Image Recognition||
|8|[1601.06759](http://cn.arxiv.org/abs/1601.06759)|Pixel Recurrent Neural Networks||
|9|[1602.07261](http://cn.arxiv.org/abs/1602.07261)|Inception-v4, Inception-ResNet and the Impact of Residual Connections on  Learning||
|10|[1603.05027](http://cn.arxiv.org/abs/1603.05027)|Identity Mappings in Deep Residual Networks||
|11|[1604.02878](http://cn.arxiv.org/abs/1604.02878)|Joint Face Detection and Alignment using Multi-task Cascaded  Convolutional Networks|mtcnn|
|12|[1609.03605](http://cn.arxiv.org/abs/1609.03605)|Detecting Text in Natural Image with Connectionist Text Proposal Network||
|13|[1611.02200](http://cn.arxiv.org/abs/1611.02200)|Unsupervised Cross-Domain Image Generation||
|14|[1703.10593](http://cn.arxiv.org/abs/1703.10593)|Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial  Networks||
|15|[1704.02470](http://cn.arxiv.org/abs/1704.02470)|DSLR-Quality Photos on Mobile Devices with Deep Convolutional Networks||
|16|[1704.03549](http://cn.arxiv.org/abs/1704.03549)|Attention-based Extraction of Structured Information from Street View  Imagery|attention-ocr|
|17|[1704.04861](http://cn.arxiv.org/abs/1704.04861)|MobileNets: Efficient Convolutional Neural Networks for Mobile Vision  Applications||
|18|[1706.03059](http://cn.arxiv.org/abs/1706.03059)|Depthwise Separable Convolutions for Neural Machine Translation||
|19|[1706.03762](http://cn.arxiv.org/abs/1706.03762)|Attention Is All You Need||
|20|[1706.05137](http://cn.arxiv.org/abs/1706.05137)|One Model To Learn Them All||
|21|[1707.07012](http://cn.arxiv.org/abs/1707.07012)|Learning Transferable Architectures for Scalable Image Recognition||
|22|[1708.05509](http://cn.arxiv.org/abs/1708.05509)|Towards the Automatic Anime Characters Creation with Generative  Adversarial Networks||
|23|[1708.02002](http://cn.arxiv.org/abs/1708.02002)|Focal Loss for Dense Object Detection|RetinaNet|
|24|[1710.10196](http://cn.arxiv.org/abs/1710.10196)|Progressive Growing of GANs for Improved Quality, Stability, and  Variation||
|25|[1712.00559](http://cn.arxiv.org/abs/1712.00559)|Progressive Neural Architecture Search||
|26|[1801.04381](http://cn.arxiv.org/abs/1801.04381)|MobileNetV2: Inverted Residuals and Linear Bottlenecks||
|27|[1801.09797](http://cn.arxiv.org/abs/1801.09797)|Discrete Autoencoders for Sequence Models||
|28|[1801.10198](http://cn.arxiv.org/abs/1801.10198)|Generating Wikipedia by Summarizing Long Sequences||
|29|[1802.02611](http://cn.arxiv.org/abs/1802.02611)|Encoder-Decoder with Atrous Separable Convolution for Semantic Image  Segmentation||
|30|[1802.05751](http://cn.arxiv.org/abs/1802.05751)|Image Transformer||
|31|[1803.02155](http://cn.arxiv.org/abs/1803.02155)|Self-Attention with Relative Position Representations||
|32|[1803.03382](http://cn.arxiv.org/abs/1803.03382)|Fast Decoding in Sequence Models using Discrete Latent Variables||
|33|[1803.07416](http://cn.arxiv.org/abs/1803.07416)|Tensor2Tensor for Neural Machine Translation|tensor2tensor|
|34|[1804.00247](http://cn.arxiv.org/abs/1804.00247)|Training Tips for the Transformer Model||
|35|[1804.04235](http://cn.arxiv.org/abs/1804.04235)|Adafactor: Adaptive Learning Rates with Sublinear Memory Cost||
