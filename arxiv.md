
# arxiv

|#|id|title|note|
|-|-|-|-|
|1|[1312.2249](http://cn.arxiv.org/abs/1312.2249)|Scalable Object Detection using Deep Neural Networks||
|2|[1406.2661](http://cn.arxiv.org/abs/1406.2661)|Generative Adversarial Networks|GAN|
|3|[1409.1556](http://cn.arxiv.org/abs/1409.1556)|Very Deep Convolutional Networks for Large-Scale Image Recognition||
|4|[1409.4842](http://cn.arxiv.org/abs/1409.4842)|Going Deeper with Convolutions||
|5|[1502.03167](http://cn.arxiv.org/abs/1502.03167)|Batch Normalization: Accelerating Deep Network Training by Reducing  Internal Covariate Shift||
|6|[1503.03832](http://cn.arxiv.org/abs/1503.03832)|FaceNet: A Unified Embedding for Face Recognition and Clustering|facenet|
|7|[1511.06434](http://cn.arxiv.org/abs/1511.06434)|Unsupervised Representation Learning with Deep Convolutional Generative  Adversarial Networks|DCGAN|
|8|[1512.00567](http://cn.arxiv.org/abs/1512.00567)|Rethinking the Inception Architecture for Computer Vision||
|9|[1512.03385](http://cn.arxiv.org/abs/1512.03385)|Deep Residual Learning for Image Recognition||
|10|[1601.06759](http://cn.arxiv.org/abs/1601.06759)|Pixel Recurrent Neural Networks||
|11|[1602.07261](http://cn.arxiv.org/abs/1602.07261)|Inception-v4, Inception-ResNet and the Impact of Residual Connections on  Learning||
|12|[1603.05027](http://cn.arxiv.org/abs/1603.05027)|Identity Mappings in Deep Residual Networks||
|13|[1604.02878](http://cn.arxiv.org/abs/1604.02878)|Joint Face Detection and Alignment using Multi-task Cascaded  Convolutional Networks|mtcnn|
|14|[1609.03605](http://cn.arxiv.org/abs/1609.03605)|Detecting Text in Natural Image with Connectionist Text Proposal Network||
|15|[1611.02200](http://cn.arxiv.org/abs/1611.02200)|Unsupervised Cross-Domain Image Generation||
|16|[1701.07875](http://cn.arxiv.org/abs/1701.07875)|Wasserstein GAN|WGAN|
|17|[1703.10593](http://cn.arxiv.org/abs/1703.10593)|Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial  Networks||
|18|[1704.02470](http://cn.arxiv.org/abs/1704.02470)|DSLR-Quality Photos on Mobile Devices with Deep Convolutional Networks||
|19|[1704.03549](http://cn.arxiv.org/abs/1704.03549)|Attention-based Extraction of Structured Information from Street View  Imagery|attention-ocr|
|20|[1704.04861](http://cn.arxiv.org/abs/1704.04861)|MobileNets: Efficient Convolutional Neural Networks for Mobile Vision  Applications||
|21|[1706.03059](http://cn.arxiv.org/abs/1706.03059)|Depthwise Separable Convolutions for Neural Machine Translation||
|22|[1706.03762](http://cn.arxiv.org/abs/1706.03762)|Attention Is All You Need||
|23|[1706.05137](http://cn.arxiv.org/abs/1706.05137)|One Model To Learn Them All||
|24|[1707.07012](http://cn.arxiv.org/abs/1707.07012)|Learning Transferable Architectures for Scalable Image Recognition||
|25|[1708.05509](http://cn.arxiv.org/abs/1708.05509)|Towards the Automatic Anime Characters Creation with Generative  Adversarial Networks||
|26|[1708.02002](http://cn.arxiv.org/abs/1708.02002)|Focal Loss for Dense Object Detection|RetinaNet|
|27|[1710.10196](http://cn.arxiv.org/abs/1710.10196)|Progressive Growing of GANs for Improved Quality, Stability, and  Variation||
|28|[1711.09020](http://cn.arxiv.org/abs/1711.09020)|StarGAN: Unified Generative Adversarial Networks for Multi-Domain  Image-to-Image Translation||
|29|[1712.00559](http://cn.arxiv.org/abs/1712.00559)|Progressive Neural Architecture Search||
|30|[1801.04381](http://cn.arxiv.org/abs/1801.04381)|MobileNetV2: Inverted Residuals and Linear Bottlenecks||
|31|[1801.09797](http://cn.arxiv.org/abs/1801.09797)|Discrete Autoencoders for Sequence Models||
|32|[1801.10198](http://cn.arxiv.org/abs/1801.10198)|Generating Wikipedia by Summarizing Long Sequences||
|33|[1802.02611](http://cn.arxiv.org/abs/1802.02611)|Encoder-Decoder with Atrous Separable Convolution for Semantic Image  Segmentation||
|34|[1802.05751](http://cn.arxiv.org/abs/1802.05751)|Image Transformer||
|35|[1803.02155](http://cn.arxiv.org/abs/1803.02155)|Self-Attention with Relative Position Representations||
|36|[1803.03382](http://cn.arxiv.org/abs/1803.03382)|Fast Decoding in Sequence Models using Discrete Latent Variables||
|37|[1803.07416](http://cn.arxiv.org/abs/1803.07416)|Tensor2Tensor for Neural Machine Translation|tensor2tensor|
|38|[1804.00247](http://cn.arxiv.org/abs/1804.00247)|Training Tips for the Transformer Model||
|39|[1804.04235](http://cn.arxiv.org/abs/1804.04235)|Adafactor: Adaptive Learning Rates with Sublinear Memory Cost||
